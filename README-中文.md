# YOLOv5.5 Detection with C#
---
**ç®€ä»‹:**
æœ¬é¡¹ç›®ä½¿ç”¨YOLOv5sæ¨¡å‹ï¼Œç”¨è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè¯†åˆ«LEDèŠ¯ç‰‡ï¼Œå¹¶ä¸”å°†ç½‘ç»œåœ¨C#ä¸­é€šè¿‡OpencvSharpçš„DNNæ¨¡å—è¿›è¡Œè°ƒç”¨æ¨ç†ï¼Œå°†ç¥ç»ç½‘ç»œåµŒå…¥åˆ°å®é™…çš„å·¥ç¨‹é¡¹ç›®ä¸­ã€‚  
**ä»»åŠ¡:** 
è¯†åˆ«LEDèŠ¯ç‰‡ï¼Œå¹¶ä¸”åœ¨C#ä¸­è¿›è¡Œæ¨ç†ã€‚  

---
**ç›®å½•ï¼š**
- [æ•°æ®é‡‡é›†](#1-æ•°æ®é‡‡é›†)
- [æ•°æ®é›†åˆ¶ä½œ](#2-æ•°æ®é›†åˆ¶ä½œ)
- [yoloæ¨¡å‹](#3-yoloæ¨¡å‹)
- [è®­ç»ƒåŠæ¨ç†](#4-è®­ç»ƒåŠæ¨ç†)
- [å¯¼å‡ºonnxæ¨¡å‹](#5-å¯¼å‡ºonnxæ¨¡å‹)
- [CSharpä¸­è°ƒç”¨onnxæ¨¡å‹](#6-csharpä¸­è°ƒç”¨onnxæ¨¡å‹)
- [[option]å¤šçº¿ç¨‹]()
---
## 1 æ•°æ®é‡‡é›† 
- ä½¿ç”¨å®é™…æ‘„åƒå¤´è¿›è¡Œé‡‡é›†çœŸå®çš„å›¾åƒï¼š  
  æ•°é‡ï¼š42 images  
<div align=center><img src="https://github.com/lin-tea/YOLOv5DetectionWithCSharp/blob/main/Pictures/datasets.png" width="70%" height="70%"></div>

## 2 æ•°æ®é›†åˆ¶ä½œ
- **æ•°æ®é›†åˆ’åˆ†**ï¼štraining:valid:test = 8:1:2
- **åˆ¶ä½œæ ‡ç­¾**ï¼š
  å·¥å…·ï¼š[labelImg](https://github.com/tzutalin/labelImg)
  æ ‡ç­¾æ–‡ä»¶: ```name.txt```ï¼Œæ¯ä¸€è¡Œä¸º ç±»åˆ« ä¸­å¿ƒx ä¸­å¿ƒy å®½ é«˜,åå­—nameå’Œå›¾ç‰‡ name.jpg å¯¹åº”ã€‚
    ```
    class x_center y_center width height
    ...
    ```
  1. åœ¨Pythonç¯å¢ƒä¸­å®‰è£…labelimg.
    ```shell
      pip install labelimg
    ```
  2. åˆ†å¥½æ•°æ®é›†åˆç»“æ„å¦‚ä¸‹ï¼š(è¿™é‡Œæ‰‹åŠ¨åˆ†æ•°æ®é›†)
    ```
    data/
        |-images/
            |-train/   
            |-valid/
        |-labels/
            |-train/
            |-valid/
    ```
  åˆ›å»ºç±»åˆ«æ–‡ä»¶(.txt),æ¯ä¸€è¡Œå†™ä¸€ç§ç±»åˆ«åç§°
  è¿™é‡Œåˆ›å»ºclasses.txtæ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š
    ```txt
    chip
    ```
  3. åœ¨ data/ æ–‡ä»¶å¤„æ‰“å¼€CMDã€ç»ˆç«¯ï¼Œå¦‚æœæ˜¯ä½¿ç”¨condaå®‰è£…çš„pythonç¯å¢ƒï¼Œæ³¨æ„æ¿€æ´»ç¯å¢ƒã€‚
    ```python
      >(conda activate [your-env-name])
      >labelimg data/images/train classes.txt
    ```
  å¯ä»¥çœ‹è§å¦‚ä¸‹å›¾ï¼Œé€‰æ‹©æ ‡ç­¾æ ¼å¼ä¸ºyoloï¼Œä¿å­˜è·¯å¾„ä¸º data/labels/trainï¼Œæ ‡ç­¾ï¼Œcost time!  
  <div align=center><img src="https://github.com/lin-tea/YOLOv5DetectionWithCSharp/blob/main/Pictures/labeling.png" width="50%" height="50%"></div>
  
## 3 yoloæ¨¡å‹
- **ä»€ä¹ˆæ˜¯YOLOvæ¨¡å‹ï¼Ÿ** see [Blog,Searchï¼Œæœ‰å¾ˆå¤šå¤§ä½¬å†™çš„ä¼˜ç§€çš„åšå®¢]()  
- **ä¸‹è½½yolov5.5å·¥ç¨‹æ–‡ä»¶**([ç‚¹æˆ‘ä¸‹è½½](https://github.com/ultralytics/yolov5/releases/tag/v5.0)),ä¸‹è½½æºæ–‡ä»¶ä»¥åŠé€‰æ‹©æƒé‡æ–‡ä»¶ï¼Œè¿™é‡Œé€‰æ‹©æƒé‡æ–‡ä»¶ä¸º**YOLOv5s**ã€‚
  <!-- Unzip Sources Zip file, In VSCode we can open this project and see:  -->
  è§£å‹æºæ–‡ä»¶ï¼Œåœ¨vscodeæ‰“å¼€å·¥ç¨‹æ–‡ä»¶ï¼š  
   <div align=center>
  <img name="YOLOv5 Og Project" src="https://github.com/lin-tea/YOLOv5DetectionWithCSharp/blob/main/Pictures/originYOLO.png" width="50%" height="50%">
</div>

- **é…ç½®è‡ªå·±çš„å·¥ç¨‹æ–‡ä»¶**:
  - dataæ–‡ä»¶ï¼šä¿å­˜æ•°æ®æ–‡ä»¶é…ç½® .yaml æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®é›†ã€è®­ç»ƒç›®æ ‡ï¼Œå»ºç«‹è‡ªå·±çš„dataé…ç½®æ–‡ä»¶ï¼Œè¿™ä¸ªé¡¹ç›®é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š
    ```yaml
    # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
    # the project will auto go to ../data/labels/train/ to get labels.
    train: ../data/images/train/  # train images  
    val: ../data/images/valid/  # valid images  

    # number of classes
    nc: 1

    # class names
    names: [ 'chip' ]  
    ```
  
  - modelé…ç½®æ–‡ä»¶ï¼šæ ¹æ®é€‰æ‹©æ¨¡å‹ï¼Œåœ¨/model/æ–‡ä»¶å¤¹ä¸­ï¼Œé€‰æ‹©ç›¸åº”çš„é…ç½®æ–‡ä»¶ï¼Œè¿™é‡Œé€‰æ‹©```yolov5s.yaml```æ–‡ä»¶ï¼Œå¤åˆ¶ä¿®æ”¹åï¼Œåªä¿®æ”¹ parametersä¸­çš„ncå‚æ•°ä¸º1ï¼Œå³ç±»åˆ«æ•°é‡ï¼Œä¿®æ”¹åå¦‚ä¸‹ï¼š
    ```yaml
      # parameters
      nc: 1  # number of classes
      depth_multiple: 0.33  # model depth multiple
      width_multiple: 0.50  # layer channel multiple
      # anchors æ¨¡å‹é”šæ¡†
      anchors:
        - [10,13, 16,30, 33,23]  # P3/8
        - [30,61, 62,45, 59,119]  # P4/16
        - [116,90, 156,198, 373,326]  # P5/32
      # æ¡†æ¶ä¸å˜
      # YOLOv5 backbone
      backbone:
      # YOLOv5 head
    ```
  
  - ä¸‹è½½é¢„è®­ç»ƒæƒé‡([ç‚¹æˆ‘ä¸‹è½½](https://github.com/ultralytics/yolov5/releases/tag/v5.0)),æ·»åŠ åˆ°å·¥ç¨‹æ–‡ä»¶ä¸­  
- **pythonç¯å¢ƒ**: `python>=3.8`
    ```shell
      > pip install -r requirements.txt
    ```
## 4 è®­ç»ƒåŠæ¨ç†
- **ä¿®æ”¹ ```train.py``` æ–‡ä»¶**
  ä¸»è¦ä¿®æ”¹å‚æ•°ï¼š
  ```
    --weights: ä¸‹è½½çš„é¢„è®­ç»ƒæƒé‡åœ°å€
    --cfg: modelé…ç½®æ–‡ä»¶åœ°å€ï¼Œæ­¥éª¤3åˆ›å»ºçš„é…ç½®æ–‡ä»¶ï¼Œå¦‚yolov5s.yaml
    --data: dataé…ç½®æ–‡ä»¶åœ°å€
    --batch-sizeï¼šæ ¹æ®å®é™…æƒ…å†µ
    --img sizeï¼š32çš„å€æ•°é»˜è®¤640x640
    --epochs: æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©
    --device: GPUæ›´å¿«
    --workersï¼šçº¿ç¨‹
  ```
  ä¿®æ”¹åå¦‚ä¸‹,(åªæ˜¾ç¤ºæ”¹å˜éƒ¨åˆ†)ï¼š
  ```python
    if __name__ == '__main__':
      parser = argparse.ArgumentParser()
      parser.add_argument('--weights', type=str, default='yolov5-5.0/weights/yolov5s.pt', help='initial weights path')
      parser.add_argument('--cfg', type=str, default='yolov5-5.0/models/myyolov5s.yaml', help='model.yaml path')
      parser.add_argument('--data', type=str, default='yolov5-5.0/data/chips.yaml', help='data.yaml path')
      parser.add_argument('--epochs', type=int, default=500)
      parser.add_argument('--batch-size', type=int, default=4, help='total batch size for all GPUs')
      parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')
      parser.add_argument('--device', default='0', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
      parser.add_argument('--workers', type=int, default=2, help='maximum number of dataloader workers')
  ```
- **Run!**ï¼šè¿è¡Œ`train.py`ç¨‹åº And **Wait... Get yourself some Tea ğŸµand hear win~win~win!**
   è®­ç»ƒç»“æŸåï¼šä¼šåœ¨å½“å‰è·¯å¾„ä¸‹ï¼Œç”Ÿæˆ```run/train/```æ–‡ä»¶å¤¹è¾“å‡ºè®­ç»ƒç»“æœã€æƒé‡:
   <div align=center>
    <img name="TrainOutputFile" src="https://github.com/lin-tea/YOLOv5DetectionWithCSharp/blob/main/Pictures/TrainOutput.png" width="70%" height="70%"></div>

   æƒé‡ä¿å­˜åœ¨```./run/train/weight/```ä¸­ï¼Œä½ å°†å¯ä»¥çœ‹åˆ°`best.pt`å’Œ`last.pt`ä¸¤ä¸ªptæ¨¡å‹æ–‡ä»¶ã€‚
- **Detect!**: è·Ÿè®­ç»ƒæ—¶ç±»ä¼¼ï¼Œæ‰“å¼€`detect.py`æ–‡ä»¶ï¼ŒåŒæ ·éœ€è¦ä¿®æ”¹ä¸€äº›å‚æ•°ï¼Œç„¶åç›´æ¥runå°±è¡Œï¼š  
    ```
      --weight   ;è®­ç»ƒåçš„`.pt`æƒé‡æ–‡ä»¶
      --source   ;æ¨ç†å›¾ç‰‡æˆ–è€…è§†é¢‘
      --img-size ;æ¨¡å‹è¾“å…¥å›¾ç‰‡å¤§å°
      [optional] --conf-thres  ;ç½®ä¿¡åº¦
      [optional] --iou-thres   ;ioué˜ˆå€¼
      [optional] --device
    ```  
    ä¿®æ”¹åå¦‚ä¸‹ï¼š  
    ```python
    if __name__ == '__main__':
      parser = argparse.ArgumentParser()
      parser.add_argument('--weights', nargs='+', type=str, default='runs\\train\\exp5\\weights\\best.pt', help='model.pt path(s)')
      parser.add_argument('--source', type=str, default='yolov5-5.0\\myDatasets2\\chip\\images\\test\\8.jpg', help='source')  # file/folder, 0 for webcam
      parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')
      parser.add_argument('--conf-thres', type=float, default=0.8, help='object confidence threshold')
      parser.add_argument('--iou-thres', type=float, default=0.45, help='IOU threshold for NMS')
      parser.add_argument('--device', default='0', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    ```  
    å¾—åˆ°ç»“æœå¦‚ä¸‹ï¼š  
    <div align=center>
      <img name="DetectImage" src="https://github.com/lin-tea/YOLOv5DetectionWithCSharp/blob/main/Pictures/detectImg.jpg" width="60%" height="60%"></div>  
    å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡ä½¿ç”¨çš„æ•°æ®é›†åˆå°ï¼Œä½†ä»è¡¨ç°ä¸é”™ï¼Œåªä¸€å¼ å›¾ç‰‡ï¼Œåœ¨æˆ‘çš„ç”µè„‘(Intel i7-8565U)ä¸Šç”¨CPUä¸Šæ¨ç†0.08s,ç”»å›¾,0.11så·¦å³ã€‚
## 5 å¯¼å‡ºonnxæ¨¡å‹  
- **YOLOv5æ¨¡å‹æ¦‚è¿°**: YOLOv5.5åœ¨ä¸‰ç§ä¸åŒçš„å¤§å°çš„ç‰¹å¾å›¾è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œä»¥æ¯ä¸€ä¸ªç‰¹å¾å›¾çš„pixieä¸ºä¸­å¿ƒï¼Œç”¨ä¸‰ç§ä¸åŒé•¿å®½æ¯”çš„anchorè¿›è¡Œé¢„æµ‹ï¼ŒåŸæœ¬çš„ç½‘ç»œè¾“å‡ºå¯¹å¯¹åº”æ¯ä¸€ä¸ªç‰¹å¾å›¾ä¸Šçš„æ¯ä¸€ä¸ªåƒç´ ï¼Œè¾“å‡ºä¸€ä¸ªé¢„æµ‹å‘é‡{x,y,h,w,confidence,[classify results]}ï¼Œé•¿åº¦ä¸º`4+1+num of classes`ã€‚`detect`ç”¨confidenceä»¥åŠnmsç®—æ³•å¯¹å„ç§é¢„æµ‹é”šæ¡†è¿›è¡Œç­›é€‰ã€‚
  - å¯¹äºé¢„æµ‹ç»“æœçš„ç›®æ ‡æ¡†å›å½’ï¼šæ ¹æ®å·¥ç¨‹æ–‡ä»¶ä¸­`model/yolo.py/`æ–‡ä»¶ä¸­çš„`Detect.forward()`éƒ¨åˆ†ï¼Œå…¶ä»£ç å¦‚ä¸‹:  
    ```python []
        for i in range(self.nl):
            x[i] = self.m[i](x[i])  # conv
            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            if not self.training:  # inference
                if self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)

                y = x[i].sigmoid()
                y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
                y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
                z.append(y.view(bs, -1, self.no))
        return x if self.training else (torch.cat(z, 1), x)
    ```  

    ![1](http://latex.codecogs.com/svg.latex?\begin{cases}x=(2Sigmoid(x)-0.5+c)*stride\\\\y=(2Sigmoid(y)-0.5+r)*stride\\\\h=(2Sigmoid(h))^2*anchor_h\\\\w=(2Sigmoid(w))^2*anchor_w\\\\\end{cases})  
    - cè¡¨ç¤ºå½“å‰ä½ç½®åœ¨ç‰¹å¾å›¾ä¸Šçš„å®½åº¦åæ ‡(å³åƒç´ åæ ‡)ï¼Œè¡¨ç¤ºåç§»é‡
    - rè¡¨ç¤ºå½“å‰ä½ç½®åœ¨ç‰¹å¾å›¾ä¸Šçš„é«˜åº¦åæ ‡(å³åƒç´ åæ ‡)ï¼Œè¡¨ç¤ºåç§»é‡
    - strideï¼Œå‹ç¼©åˆ°ä¸åŒå¤§å°çš„ç‰¹å¾å›¾æ—¶çš„ä½¿ç”¨ä¸åŒstride
    - anchor:anchor_hã€anchor_w,ä¸åŒanchorå¤§å°å‚æ•°
    - tipsï¼šå‚è€ƒæ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œanchor={h1,h2,h3,w1,w2,w3},stride={8,16,32}
- **ä¿®æ”¹å·¥ç¨‹æ–‡ä»¶ä¸­çš„åˆ‡ç‰‡æ“ä½œ**

- **æŠŠç»“æœè¾“å‡ºçš„ä¸‰ä¸ªç‰¹å¾å›¾concatæˆäºŒç»´çš„å¼ é‡**  
  - æ­£å¸¸yolov5è¾“å‡ºç»“æ„:   
      å‡è®¾ç½‘ç»œè¾“å…¥å¤§å°ä¸º[h,w],ç‰¹å¾å›¾æ­¥é•¿stride={s1,s2,s3}ï¼Œanchoræ•°é‡ä¸º3:    
      `1x(5+num of classes)x3((h/s1)x(w/s1)+(h/s2)x(w/s2)+(h/s3)x(w/s3))`  
  - ä¿®æ”¹ï¼šflattenæˆäºŒç»´ï¼Œå¯¹strideã€anchoråœ¨(5+num of classes)ç»´åº¦ä¸Šæ‹¼æ¥ï¼Œå¯¹äºyolov5.5sæœ€ç»ˆè¾“å‡ºæ ¼å¼ä¸ºï¼š25200x(5+num of classes)  
  - (å½“ç„¶ä¹Ÿå¯ä»¥ä¸ä¿®æ”¹ï¼Œåªæ˜¯åç»­å¯¹ç»“æœå¤„ç†éœ€è¿›è¡Œä¸€å®šçš„æ”¹å˜)  
- **Output ONNX æ¨¡å‹ï¼**
  
## 6 CSharpä¸­è°ƒç”¨onnxæ¨¡å‹
  **tool**: `opencvsharp.dnn`[Here](https://github.com/shimat/opencvsharp/releases/tag/4.5.3.20211228).  

## Reference:
  [1] [YOLOv5 Document](https://docs.ultralytics.com/).  
  [2] What is Anchor? [Anchor Boxes for Object detection](https://stackoverflow.com/questions/70227234/anchor-boxes-for-object-detection).
  
